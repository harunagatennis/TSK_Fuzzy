{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "781688b4-4c4f-4747-9ff5-7edf36c580c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#汎用的なTSKファジィ推論モデルを構築する\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28df0713-8519-497d-acc5-6acd4c1251a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#各種データを読み込む\n",
    "original_data = pd.read_csv('fuzzy_diabetes2_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd9b00c6-abc0-4f34-ae6c-949475f461a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#次に各種データに対して正規化を行っていく\n",
    "#ただし、例外のカラムを設けておく\n",
    "#正規化をあらかじめ行いたいカラムについてはその例外にカラム名を付与しておく\n",
    "\n",
    "#まず例外カラム名の制定\n",
    "#各種データごとに確認・変更してほしい箇所\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "exception_columns = []\n",
    "for clm in original_data.columns:\n",
    "    if clm not in exception_columns:\n",
    "        original_data[clm] = (original_data[clm] - original_data[clm].min()) / (original_data[clm].max() - original_data[clm].min())\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40f5dd19-35e6-4210-88c2-d4d191e9bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここで各種データをnumpy配列に変換しておく\n",
    "np_original_data = np.array(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3837a320-8764-4b83-9362-b8c48ad607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#次に教師データとテストデータに分割する\n",
    "#ここでは教師データ:テストデータを5:5とする\n",
    "\n",
    "#教師データ、テストデータの割合の設定\n",
    "#各種データごとに確認・変更してほしい箇所\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "TEACHER_SIZE_RATIO = 5\n",
    "TEST_SIZE_RATIO = 5\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "#上で定めた割合に基づき、教師データ数とテストデータ数を求める\n",
    "TEACHER_SIZE = ((int)(len(np_original_data) * ((TEACHER_SIZE_RATIO) / (TEACHER_SIZE_RATIO + TEST_SIZE_RATIO)))) + 1\n",
    "TEST_SIZE = len(np_original_data) - TEACHER_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec78cf50-ce96-48a7-a6db-bef1f4c82aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#次に教師データとテストデータに分割する\n",
    "teacher_data = np_original_data[:TEACHER_SIZE,:]\n",
    "test_data = np_original_data[TEACHER_SIZE:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905c9251-a898-4157-aa71-f57432231b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#元データの入力データと出力データの合計の属性数を求める\n",
    "NUMBER_OF_DATA_VARIATION = len(teacher_data[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95e9465e-5063-4129-b51b-d69e09006ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数と被説明変数とに分割する\n",
    "#被説明変数は最後の要素のみとする\n",
    "x_teacher_data = teacher_data[:,:NUMBER_OF_DATA_VARIATION-1]\n",
    "y_teacher_data = teacher_data[:,NUMBER_OF_DATA_VARIATION-1]\n",
    "x_test_data = test_data[:,:NUMBER_OF_DATA_VARIATION-1]\n",
    "y_test_data = test_data[:,NUMBER_OF_DATA_VARIATION-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d997351f-09fc-4e3c-b35d-9e0d866799d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#次にファジィ分割数と入力データの属性数からファジィルールの総数を求める\n",
    "#各種データごとに確認・変更してほしい箇所\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "NUMBER_OF_FUZZY_PARTITION = 3\n",
    "NUMBER_OF_INPUT = NUMBER_OF_DATA_VARIATION - 1\n",
    "NUMBER_OF_FUZZY_RULE = NUMBER_OF_FUZZY_PARTITION ** NUMBER_OF_INPUT\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4470338e-b56b-459a-85bc-2253307a9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#前件部の初期値と後件部の初期値を設定する\n",
    "#前件部の中心と幅は、ルール数×各ルールにおける入力変数の数\n",
    "antecedent_center = np.empty((NUMBER_OF_FUZZY_RULE, NUMBER_OF_INPUT))\n",
    "antecedent_broad = np.empty((NUMBER_OF_FUZZY_RULE, NUMBER_OF_INPUT))\n",
    "consequent_part = np.empty((NUMBER_OF_FUZZY_RULE, TEACHER_SIZE+1))\n",
    "consequent = np.zeros(NUMBER_OF_FUZZY_RULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12f89dca-7525-4517-9df7-3e592ed8ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#まず前件部の値を初期化する\n",
    "#ただし、ここは簡略型ファジィ推論と同様\n",
    "for i in range(NUMBER_OF_FUZZY_RULE):\n",
    "    for j in range(NUMBER_OF_INPUT):\n",
    "        if ((int)(i / (NUMBER_OF_FUZZY_PARTITION ** (NUMBER_OF_INPUT - (j+1))))) % NUMBER_OF_FUZZY_PARTITION == 0:\n",
    "            antecedent_center[i,j] = 0\n",
    "            antecedent_broad[i,j] = 1\n",
    "        elif ((int)(i / (NUMBER_OF_FUZZY_PARTITION ** (NUMBER_OF_INPUT - (j+1))))) % NUMBER_OF_FUZZY_PARTITION == 1:\n",
    "            antecedent_center[i,j] = 0.5\n",
    "            antecedent_broad[i,j] = 0.5\n",
    "        else:\n",
    "            antecedent_center[i,j] = 1\n",
    "            antecedent_broad[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02980774-0638-44d5-afec-e9d107866403",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47\n",
      " 0.47 0.47 0.47 0.47 0.47]\n"
     ]
    }
   ],
   "source": [
    "#次に後件部の値を初期化する\n",
    "#後件部の値は簡略型とは違う\n",
    "#教師データに使う73データと定数の74項から後件部実数値は構成される\n",
    "#74番目の値は定数とする\n",
    "for i in range(NUMBER_OF_FUZZY_RULE):\n",
    "    for j in range(TEACHER_SIZE+1):\n",
    "        consequent_part[i,j] = 0.01\n",
    "for i in range(NUMBER_OF_FUZZY_RULE):\n",
    "    for j in range(TEACHER_SIZE+1):\n",
    "        if j == TEACHER_SIZE:\n",
    "            consequent[i] = consequent[i] + consequent_part[i,j]\n",
    "        else:\n",
    "            consequent[i] = consequent[i] + (consequent_part[i,j] * y_teacher_data[j])\n",
    "            #print(consequent_part[i,j] * y_teacher_data[j])\n",
    "print(consequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3b468-09c0-4dc6-bf1c-98402aafcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#次に教師データを用いて学習を行う\n",
    "#ここでは前件部の更新はフェードアウトしておく\n",
    "#学習回数を設定する\n",
    "TRAIN_TIME = 1000\n",
    "\n",
    "mean_squared_error = 0\n",
    "\n",
    "#学習係数を設定する\n",
    "#LEARNING_ANTECEDENT_BROAD = 0.005\n",
    "#LEARNING_ANTECEDENT_CENTER = 0.005\n",
    "LEARNING_CONSEQUENT = 0.001\n",
    "#まず、各ルールに基づいて入力変数をファジィ化（メンバシップ関数に代入）する\n",
    "membership_function = np.empty((NUMBER_OF_FUZZY_RULE, NUMBER_OF_INPUT))\n",
    "\n",
    "for time in range(TRAIN_TIME):\n",
    "    for i in range(TEACHER_SIZE):\n",
    "        delta_broad = np.empty((NUMBER_OF_FUZZY_RULE, NUMBER_OF_INPUT))\n",
    "        delta_center = np.empty((NUMBER_OF_FUZZY_RULE, NUMBER_OF_INPUT))\n",
    "        #適合度を初期化する\n",
    "        adaptability = np.ones(NUMBER_OF_FUZZY_RULE)\n",
    "        for j in range(NUMBER_OF_FUZZY_RULE):\n",
    "            for k in range(NUMBER_OF_INPUT):\n",
    "                if(x_teacher_data[i,k] >= antecedent_center[j,k] - antecedent_broad[j,k]) and x_teacher_data[i,k] <= antecedent_center[j,k]:\n",
    "                    membership_function[j,k] = (x_teacher_data[i,k] - (antecedent_center[j,k] - antecedent_broad[j,k])) / antecedent_broad[j,k]\n",
    "                    #delta_broad[j,k] = (antecedent_center[j,k] - x_teacher_data[i,k]) / (antecedent_broad[j,k]**2)\n",
    "                    #delta_center[j,k] = -(1 / antecedent_broad[j,k])\n",
    "                elif(x_teacher_data[i,k] > antecedent_center[j,k]) and (x_teacher_data[i,k] <= antecedent_center[j,k] + antecedent_broad[j,k]):\n",
    "                    membership_function[j,k] = -(x_teacher_data[i,k] - (antecedent_center[j,k] + antecedent_broad[j,k])) / antecedent_broad[j,k]\n",
    "                    #delta_broad[j,k] = -(antecedent_center[j,k] - x_teacher_data[i,k]) / (antecedent_broad[j,k]**2)\n",
    "                    #delta_center[j,k] = 1 / antecedent_broad[j,k]\n",
    "            #各ルールにおける適合度を求める\n",
    "            for k in range(NUMBER_OF_INPUT):\n",
    "                adaptability[j] = adaptability[j] * membership_function[j,k]\n",
    "        #各データに対して予測結果を求める\n",
    "        output = 0\n",
    "        output = np.sum(np.dot(adaptability, consequent)) / np.sum(adaptability)\n",
    "        if(time == TRAIN_TIME-1):\n",
    "            print(output, y_teacher_data[i])\n",
    "            mean_squared_error = mean_squared_error + (output - y_teacher_data[i])**2\n",
    "            if(i == TEACHER_SIZE-1):\n",
    "                mean_squared_error = mean_squared_error / TEACHER_SIZE\n",
    "                print(\"平均二条誤差\")\n",
    "                print(mean_squared_error)\n",
    "        #出力値を求めた次に後件部と前件部の更新を行う\n",
    "        #まずは後件部の値の更新を行う\n",
    "        #consequent_partの更新を行った後に、consequentに変換を行う\n",
    "        for j in range(NUMBER_OF_FUZZY_RULE):\n",
    "            for k in range(TEACHER_SIZE + 1):\n",
    "                if k == TEACHER_SIZE:\n",
    "                    consequent_part[j,k] = consequent_part[j,k] + (LEARNING_CONSEQUENT * adaptability[j] / np.sum(adaptability)) * (y_teacher_data[i] - output)\n",
    "                else:\n",
    "                    consequent_part[j,k] = consequent_part[j,k] + (LEARNING_CONSEQUENT * adaptability[j] / np.sum(adaptability)) * (y_teacher_data[i] - output) * y_teacher_data[k]\n",
    "        #consequentの更新を行う\n",
    "        for j in range(NUMBER_OF_FUZZY_RULE):\n",
    "            consequent[j] = 0\n",
    "            for k in range(TEACHER_SIZE+1):\n",
    "                if k == TEACHER_SIZE:\n",
    "                    consequent[j] = consequent[j] + consequent_part[j,k]\n",
    "                else:\n",
    "                    consequent[j] = consequent[j] + (consequent_part[j,k] * y_teacher_data[k])\n",
    "        #次に前件部の値の更新を行う\n",
    "        #for j in range(NUMBER_OF_FUZZY_RULE):\n",
    "            #for k in range(NUMBER_OF_INPUT):\n",
    "                #antecedent_center[j,k] = antecedent_center[j,k] + (LEARNING_ANTECEDENT_CENTER * adaptability[j] / np.sum(adaptability)) * (y_teacher_data[i] - output) * (consequent[j] - output) * delta_center[j,k]\n",
    "                #antecedent_broad[j,k] = antecedent_broad[j,k] + (LEARNING_ANTECEDENT_BROAD * adaptability[j] / np.sum(adaptability)) * (y_teacher_data[i] - output) * (consequent[j] - output) * delta_broad[j,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184d3ce-fa9f-438f-a26d-92e3fb28bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#次にテストデータを用いて予測結果を比較する\n",
    "#各ルールに対して全ての入力変数データをファジィ化する\n",
    "test_membership_function = np.empty((NUMBER_OF_FUZZY_RULE, NUMBER_OF_INPUT))\n",
    "\n",
    "test_mean_squared_error = 0\n",
    "\n",
    "for i in range(TEST_SIZE):\n",
    "    #適合度を初期化する\n",
    "    test_adaptability = np.ones(NUMBER_OF_FUZZY_RULE)\n",
    "    for j in range(NUMBER_OF_FUZZY_RULE):\n",
    "        for k in range(NUMBER_OF_INPUT):\n",
    "            if(x_test_data[i,k] >= antecedent_center[j,k] - antecedent_broad[j,k]) and x_test_data[i,k] <= antecedent_center[j,k]:\n",
    "                test_membership_function[j,k] = (x_test_data[i,k] - ( antecedent_center[j,k] - antecedent_broad[j,k])) / antecedent_broad[j,k]\n",
    "            elif(x_test_data[i,k] > antecedent_center[j,k]) and (x_test_data[i,k] <= antecedent_center[j,k] + antecedent_broad[j,k]):\n",
    "                test_membership_function[j,k] = -(x_test_data[i,k] - (antecedent_center[j,k] + antecedent_broad[j,k])) / antecedent_broad[j,k]\n",
    "        #各ルールにおける適合度を求める\n",
    "        for k in range(NUMBER_OF_INPUT):\n",
    "            test_adaptability[j] = test_adaptability[j] * test_membership_function[j,k]\n",
    "    #各データに対して予測結果を求める\n",
    "    test_output = 0\n",
    "    test_output = np.sum(np.dot(test_adaptability, consequent)) / np.sum(test_adaptability)\n",
    "    print(test_output, y_test_data[i])\n",
    "    test_mean_squared_error = test_mean_squared_error + (test_output - y_test_data[i])**2\n",
    "    if(i == TEST_SIZE-1):\n",
    "        test_mean_squared_error = test_mean_squared_error / TEST_SIZE\n",
    "        print(\"平均二条誤差\")\n",
    "        print(test_mean_squared_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
